{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Serverless Agents on Cloud Run\n",
        "\n",
        "Welcome to the **Serverless Agents** workshop! In this session, we will build a production-ready, event-driven \"Micro-Agent\" system. We will leverage the power of Google Cloud's serverless ecosystem to create agents that are scalable, cost-effective, and easy to maintain.\n",
        "\n",
        "## Technologies Used\n",
        "\n",
        "> **[Google Cloud Run](https://cloud.google.com/run)**\n",
        "> Cloud Run is a fully managed compute platform that lets you run containers directly on top of Google's scalable infrastructure. It abstracts away infrastructure management, allowing you to focus on building your agents. It automatically scales up and down from zero, meaning you only pay when your code is running. In this workshop, we use Cloud Run to host our agent services, ensuring they can handle any amount of traffic without manual intervention.\n",
        "\n",
        "> **[Vertex AI & Gemini 2.5 Flash](https://cloud.google.com/vertex-ai/generative-ai/docs/models/gemini-models)**\n",
        "> Gemini 2.5 Flash is Google's latest lightweight, low-latency multimodal model designed for high-frequency tasks. It offers exceptional speed and cost-efficiency while maintaining high reasoning capabilities. We use Vertex AI to access this model, enabling our agents to process documents and generate natural language responses with enterprise-grade security and reliability.\n",
        "\n",
        "> **[Eventarc](https://cloud.google.com/eventarc)**\n",
        "> Eventarc allows you to build event-driven architectures by routing events from Google Cloud sources (like Cloud Storage) to your services. It handles the complexity of event ingestion, delivery, and security. We use Eventarc to trigger our \"Librarian\" agent instantly whenever a new file is uploaded, creating a reactive and real-time ingestion pipeline.\n",
        "\n",
        "> **[Firestore](https://cloud.google.com/firestore)**\n",
        "> Firestore is a flexible, scalable NoSQL cloud database for storing and syncing data. It keeps your data in sync across client apps through realtime listeners and offers offline support. We use Firestore as the \"Brain\" of our system, storing both the ingested knowledge (summaries) and the conversation history (short-term memory) for our agents.\n",
        "\n",
        "## Workshop Architecture\n",
        "\n",
        "We will build two distinct micro-services:\n",
        "1.  **The Librarian**: An event-driven background service. It listens for file uploads to Cloud Storage, uses Gemini to generate comprehensive summaries, and indexes them into Firestore.\n",
        "2.  **The Guide**: A user-facing chat service. It retrieves the knowledge stored by the Librarian and uses Gemini to answer user queries in a conversational manner, maintaining context via Firestore.\n",
        "\n",
        "Let's build it!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup & Authentication\n",
        "\n",
        "**Why do we need this?**\n",
        "To interact with Google Cloud resources (like Cloud Run, Firestore, etc.) from this notebook, we need to prove who we are. We use `gcloud auth login` to authenticate your personal Google account and set up \"Application Default Credentials\" (ADC). This allows the Python libraries we use later to automatically find your credentials.\n",
        "\n",
        "If you don't have a project yet:\n",
        "\n",
        "1. [Create a project](https://console.cloud.google.com/projectcreate) in the Google Cloud Console.\n",
        "2. Copy your `Project ID` from the project's [Settings page](https://console.cloud.google.com/iam-admin/settings)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "PROJECT_ID = \"[your-project-id]\"  # @param {type:\"string\", isTemplate: true}\n",
        "REGION = \"us-central1\"  # @param {type:\"string\", isTemplate: true}\n",
        "\n",
        "if PROJECT_ID == \"[your-project-id]\" or not PROJECT_ID:\n",
        "    print(\"Please specify your project id in PROJECT_ID variable.\")\n",
        "    raise KeyboardInterrupt\n",
        "\n",
        "!gcloud auth print-identity-token -q &> /dev/null || gcloud auth login --project=\"{PROJECT_ID}\" --update-adc --quiet\n",
        "\n",
        "!gcloud config set project {PROJECT_ID}\n",
        "os.environ[\"GOOGLE_CLOUD_PROJECT\"] = PROJECT_ID\n",
        "os.environ[\"GOOGLE_CLOUD_REGION\"] = REGION"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1.1 Clone Repository\n",
        "\n",
        "**Why are we doing this?**\n",
        "Google Colab is a temporary virtual machine. It starts empty. The code for our agents (`main.py`, `Dockerfile`) lives in GitHub. We need to `git clone` (download) that code into this machine so we can build and deploy it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!git clone https://github.com/sangalo20/Severless-agents-cloudrun.git\n",
        "%cd Severless-agents-cloudrun"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Enable APIs\n",
        "\n",
        "**What are these?**\n",
        "Google Cloud services are not enabled by default. We need to turn on the specific services we plan to use:\n",
        "*   `run.googleapis.com`: **Cloud Run** (to run our containers).\n",
        "*   `eventarc.googleapis.com`: **Eventarc** (to trigger the Librarian when a file is uploaded).\n",
        "*   `aiplatform.googleapis.com`: **Vertex AI** (to use the Gemini model).\n",
        "*   `firestore.googleapis.com`: **Firestore** (our database).\n",
        "*   `cloudbuild.googleapis.com`: **Cloud Build** (to build our Docker containers).\n",
        "*   `storage.googleapis.com`: **Cloud Storage** (to store the PDF files).\n",
        "*   `artifactregistry.googleapis.com`: **Artifact Registry** (to store our Docker images)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!gcloud services enable run.googleapis.com eventarc.googleapis.com aiplatform.googleapis.com firestore.googleapis.com cloudbuild.googleapis.com storage.googleapis.com artifactregistry.googleapis.com"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Create Infrastructure\n",
        "\n",
        "**The Plan:**\n",
        "1.  **Cloud Storage Bucket**: We need a place to upload our conference schedules (PDFs). This bucket will act as the \"Inbox\" for our Librarian agent.\n",
        "2.  **Permissions**: We ensure our build service account has permission to write logs, save images, access Vertex AI, and write to Firestore.\n",
        "3.  **Firestore Database**: We need a fast, serverless database to store the *summarized knowledge* and the *chat history*. We use Firestore in \"Native\" mode.\n",
        "4.  **Artifact Registry**: We need a repository to store our Docker images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "BUCKET_NAME = f\"{PROJECT_ID}-knowledge-base\"\n",
        "!gsutil mb -l {REGION} gs://{BUCKET_NAME}\n",
        "print(f\"Created bucket: {BUCKET_NAME}\")\n",
        "\n",
        "# Get Project Number and Service Account\n",
        "PROJECT_NUMBER = !gcloud projects describe {PROJECT_ID} --format='value(projectNumber)'\n",
        "PROJECT_NUMBER = PROJECT_NUMBER[0]\n",
        "SERVICE_ACCOUNT = f\"{PROJECT_NUMBER}-compute@developer.gserviceaccount.com\"\n",
        "\n",
        "# Grant permissions for Cloud Build and Runtime (Logging, Artifact Registry, Vertex AI, Firestore)\n",
        "!gcloud projects add-iam-policy-binding {PROJECT_ID} --member=serviceAccount:{SERVICE_ACCOUNT} --role=roles/logging.logWriter\n",
        "!gcloud projects add-iam-policy-binding {PROJECT_ID} --member=serviceAccount:{SERVICE_ACCOUNT} --role=roles/artifactregistry.writer\n",
        "!gcloud projects add-iam-policy-binding {PROJECT_ID} --member=serviceAccount:{SERVICE_ACCOUNT} --role=roles/storage.objectViewer\n",
        "!gcloud projects add-iam-policy-binding {PROJECT_ID} --member=serviceAccount:{SERVICE_ACCOUNT} --role=roles/aiplatform.user\n",
        "!gcloud projects add-iam-policy-binding {PROJECT_ID} --member=serviceAccount:{SERVICE_ACCOUNT} --role=roles/datastore.user\n",
        "\n",
        "# Create Firestore in Native mode (if not exists)\n",
        "!gcloud firestore databases create --location={REGION} --type=firestore-native\n",
        "\n",
        "# Create Artifact Registry Repository\n",
        "!gcloud artifacts repositories create containers --repository-format=docker --location={REGION} --description=\"Docker repository\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Build \"The Librarian\" Service\n",
        "\n",
        "**Step 1: Build Container**\n",
        "We use `gcloud builds submit` to package our python code (`librarian/main.py`) into a Docker container image. This image is stored in Artifact Registry and is ready to be deployed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "SERVICE_NAME_LIBRARIAN = \"librarian\"\n",
        "!gcloud builds submit --tag {REGION}-docker.pkg.dev/{PROJECT_ID}/containers/{SERVICE_NAME_LIBRARIAN} librarian/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4.1 Deploy \"The Librarian\" Service\n",
        "\n",
        "**Step 2: Deploy to Cloud Run**\n",
        "Now we take the image we just built and deploy it to Cloud Run. We use `--allow-unauthenticated` so that Eventarc can easily trigger it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!gcloud run deploy {SERVICE_NAME_LIBRARIAN} --image {REGION}-docker.pkg.dev/{PROJECT_ID}/containers/{SERVICE_NAME_LIBRARIAN} --region {REGION} --allow-unauthenticated"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Build \"The Guide\" Service\n",
        "\n",
        "**Step 1: Build Container**\n",
        "Similar to the Librarian, we first build the container image for the Guide service."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "SERVICE_NAME_GUIDE = \"guide\"\n",
        "!gcloud builds submit --tag {REGION}-docker.pkg.dev/{PROJECT_ID}/containers/{SERVICE_NAME_GUIDE} guide/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5.1 Deploy \"The Guide\" Service\n",
        "\n",
        "**Step 2: Deploy to Cloud Run**\n",
        "We deploy the Guide service. This service will host the chat endpoint."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!gcloud run deploy {SERVICE_NAME_GUIDE} --image {REGION}-docker.pkg.dev/{PROJECT_ID}/containers/{SERVICE_NAME_GUIDE} --region {REGION} --allow-unauthenticated"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Wire it up with Eventarc\n",
        "\n",
        "**The Magic Glue**\n",
        "Right now, the Librarian service is running, but it doesn't know when a file is uploaded. We need **Eventarc** to bridge the gap.\n",
        "\n",
        "We create a **Trigger** that says:\n",
        "*   **IF** a file is `finalized` (uploaded) ...\n",
        "*   **IN** the specific bucket `{BUCKET_NAME}` ...\n",
        "*   **THEN** send a POST request to the `{SERVICE_NAME_LIBRARIAN}` service.\n",
        "\n",
        "*Note: We also grant the necessary IAM permissions so Eventarc is allowed to call our Cloud Run service.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Grant permission to the Compute Engine service account (default for Eventarc)\n",
        "PROJECT_NUMBER = !gcloud projects describe {PROJECT_ID} --format='value(projectNumber)'\n",
        "PROJECT_NUMBER = PROJECT_NUMBER[0]\n",
        "SERVICE_ACCOUNT = f\"{PROJECT_NUMBER}-compute@developer.gserviceaccount.com\"\n",
        "\n",
        "!gcloud projects add-iam-policy-binding {PROJECT_ID} --member=serviceAccount:{SERVICE_ACCOUNT} --role=roles/eventarc.eventReceiver\n",
        "!gcloud projects add-iam-policy-binding {PROJECT_ID} --member=serviceAccount:{SERVICE_ACCOUNT} --role=roles/run.invoker\n",
        "\n",
        "# Create the trigger\n",
        "!gcloud eventarc triggers create librarian-trigger \\\n",
        "  --location={REGION} \\\n",
        "  --destination-run-service={SERVICE_NAME_LIBRARIAN} \\\n",
        "  --destination-run-region={REGION} \\\n",
        "  --event-filters=\"type=google.cloud.storage.object.v1.finalized\" \\\n",
        "  --event-filters=\"bucket={BUCKET_NAME}\" \\\n",
        "  --service-account={SERVICE_ACCOUNT}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Test it!\n",
        "\n",
        "**Let's see it in action**\n",
        "1.  **Ingestion**: We create a dummy text file (`schedule.txt`) and upload it to the bucket. This should trigger the Librarian to read it, summarize it with Gemini, and save it to Firestore.\n",
        "2.  **Chat**: We send a chat message to the Guide service. It should look up the summary in Firestore and answer our question."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1. Upload a dummy schedule\n",
        "with open(\"schedule.txt\", \"w\") as f:\n",
        "    f.write(\"DevFest Schedule:\\n10:00 AM - Keynote by Google\\n11:00 AM - Serverless Agents Workshop\\n12:00 PM - Lunch\")\n",
        "\n",
        "!gsutil cp schedule.txt gs://{BUCKET_NAME}/schedule.txt\n",
        "print(\"File uploaded. Waiting for Eventarc (approx 1-2 mins)...\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 2. Chat with the Guide\n",
        "import requests\n",
        "import time\n",
        "\n",
        "# Get Guide URL\n",
        "GUIDE_URL = !gcloud run services describe {SERVICE_NAME_GUIDE} --region {REGION} --format='value(status.url)'\n",
        "GUIDE_URL = GUIDE_URL[0]\n",
        "\n",
        "print(f\"Chatting with Guide at: {GUIDE_URL}\")\n",
        "\n",
        "query = {\"session_id\": \"test-session\", \"query\": \"What time is the Serverless Agents workshop?\"}\n",
        "response = requests.post(f\"{GUIDE_URL}/chat\", json=query)\n",
        "print(response.json())"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
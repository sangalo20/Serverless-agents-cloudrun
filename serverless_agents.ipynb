{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<table align=\"left\">\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://colab.research.google.com/github/sangalo20/Serverless-agents-cloudrun/blob/main/serverless_agents.ipynb\">\n",
        "      <img width=\"32px\" src=\"https://www.gstatic.com/pantheon/images/bigquery/welcome_page/colab-logo.svg\" alt=\"Google Colaboratory logo\"><br> Open in Colab\n",
        "    </a>\n",
        "  </td>\n",
        "</table>\n",
        "\n",
        "<div style=\"clear: both;\"></div>\n",
        "\n",
        "<b>Share to:</b>\n",
        "\n",
        "<a href=\"https://www.linkedin.com/sharing/share-offsite/?url=https%3A//github.com/sangalo20/Serverless-agents-cloudrun/blob/main/serverless_agents.ipynb\" target=\"_blank\">\n",
        "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/8/81/LinkedIn_icon.svg\" alt=\"LinkedIn logo\">\n",
        "</a>\n",
        "\n",
        "<a href=\"https://bsky.app/intent/compose?text=https%3A//github.com/sangalo20/Serverless-agents-cloudrun/blob/main/serverless_agents.ipynb\" target=\"_blank\">\n",
        "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/7/7a/Bluesky_Logo.svg\" alt=\"Bluesky logo\">\n",
        "</a>\n",
        "\n",
        "<a href=\"https://twitter.com/intent/tweet?url=https%3A//github.com/sangalo20/Serverless-agents-cloudrun/blob/main/serverless_agents.ipynb\" target=\"_blank\">\n",
        "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/5/5a/X_icon_2.svg\" alt=\"X logo\">\n",
        "</a>\n",
        "\n",
        "<a href=\"https://reddit.com/submit?url=https%3A//github.com/sangalo20/Serverless-agents-cloudrun/blob/main/serverless_agents.ipynb\" target=\"_blank\">\n",
        "  <img width=\"20px\" src=\"https://redditinc.com/hubfs/Reddit%20Inc/Brand/Reddit_Logo.png\" alt=\"Reddit logo\">\n",
        "</a>\n",
        "\n",
        "<a href=\"https://www.facebook.com/sharer/sharer.php?u=https%3A//github.com/sangalo20/Serverless-agents-cloudrun/blob/main/serverless_agents.ipynb\" target=\"_blank\">\n",
        "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/5/51/Facebook_f_logo_%282019%29.svg\" alt=\"Facebook logo\">\n",
        "</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "| | |\n",
        "|-|-|\n",
        "| Author(s) | [Sangalo Mwenyinyo](https://github.com/sangalo20) |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Serverless Agents on Cloud Run\n",
        "\n",
        "Welcome to the **Serverless Agents** on Cloud Run! In this session, we will go beyond simple chatbots and build a production-ready, event-driven **Multi-Agent System**.\n",
        "\n",
        "## Architecture\n",
        "\n",
        "**The Challenge:**\n",
        "Building a GenAI application is easy, but building one that is **scalable**, **up-to-date**, and **responsive** is hard. How do we ensure our agent knows the latest information without constantly retraining it? How do we prevent long document processing times from blocking user chat?\n",
        "\n",
        "**The Solution: Micro-Agents**\n",
        "We will solve this by decomposing our system into two specialized, independent micro-services. This \"Micro-Agent\" pattern allows us to separate the heavy lifting of data ingestion from the real-time demands of user interaction.\n",
        "\n",
        "We will build:\n",
        "1.  **The Librarian (Ingestion Agent)**: An event-driven background service. Its sole job is to listen for new information (PDFs uploaded to Cloud Storage), read it, understand it using Gemini, and file it away in our knowledge base (Firestore). It scales to zero when not in use and scales up instantly when you upload thousands of files.\n",
        "2.  **The Guide (Interface Agent)**: A user-facing chat service. It connects to the knowledge base created by the Librarian to answer user questions accurately. It maintains conversation history and provides a helpful, human-like interface.\n",
        "\n",
        "## Technologies Used\n",
        "\n",
        "> **[Google Cloud Run](https://cloud.google.com/run)**\n",
        "> Cloud Run is a fully managed compute platform that lets you run containers directly on top of Google's scalable infrastructure. It abstracts away infrastructure management, allowing you to focus on building your agents. It automatically scales up and down from zero, meaning you only pay when your code is running. In this workshop, we use Cloud Run to host our agent services, ensuring they can handle any amount of traffic without manual intervention.\n",
        "\n",
        "> **[Vertex AI & Gemini 2.5 Flash](https://cloud.google.com/vertex-ai/generative-ai/docs/models/gemini-models)**\n",
        "> Gemini 2.5 Flash is Google's latest lightweight, low-latency multimodal model designed for high-frequency tasks. It offers exceptional speed and cost-efficiency while maintaining high reasoning capabilities. We use Vertex AI to access this model, enabling our agents to process documents and generate natural language responses with enterprise-grade security and reliability.\n",
        "\n",
        "> **[Eventarc](https://cloud.google.com/eventarc)**\n",
        "> Eventarc allows you to build event-driven architectures by routing events from Google Cloud sources (like Cloud Storage) to your services. It handles the complexity of event ingestion, delivery, and security. We use Eventarc to trigger our \"Librarian\" agent instantly whenever a new file is uploaded, creating a reactive and real-time ingestion pipeline.\n",
        "\n",
        "> **[Firestore](https://cloud.google.com/firestore)**\n",
        "> Firestore is a flexible, scalable NoSQL cloud database for storing and syncing data. It keeps your data in sync across client apps through realtime listeners and offers offline support. We use Firestore as the \"Brain\" of our system, storing both the ingested knowledge (summaries) and the conversation history (short-term memory) for our agents.\n",
        "\n",
        "Let's build it!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup & Authentication\n",
        "\n",
        "**Why do we need this?**\n",
        "To interact with Google Cloud resources (like Cloud Run, Firestore, etc.) from this notebook, we need to prove who we are.\n",
        "\n",
        "**What is ADC (Application Default Credentials)?**\n",
        "ADC is a strategy used by Google Cloud libraries to automatically find your credentials. Instead of hardcoding API keys (which is insecure), ADC looks for credentials in a known location on your system. By running `gcloud auth login --update-adc`, we place your personal credentials in that location. This way, when our Python code runs `storage.Client()` or `vertexai.init()`, it automatically finds and uses your identity.\n",
        "\n",
        "If you don't have a project yet:\n",
        "\n",
        "1. [Create a project](https://console.cloud.google.com/projectcreate) in the Google Cloud Console.\n",
        "2. Copy your `Project ID` from the project's [Settings page](https://console.cloud.google.com/iam-admin/settings)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "PROJECT_ID = \"[your-project-id]\"  # @param {type:\"string\", isTemplate: true}\n",
        "REGION = \"us-central1\"  # @param {type:\"string\", isTemplate: true}\n",
        "\n",
        "if PROJECT_ID == \"[your-project-id]\" or not PROJECT_ID:\n",
        "    print(\"Please specify your project id in PROJECT_ID variable.\")\n",
        "    raise KeyboardInterrupt\n",
        "\n",
        "!gcloud auth print-identity-token -q &> /dev/null || gcloud auth login --project=\"{PROJECT_ID}\" --update-adc --quiet\n",
        "\n",
        "!gcloud config set project {PROJECT_ID}\n",
        "os.environ[\"GOOGLE_CLOUD_PROJECT\"] = PROJECT_ID\n",
        "os.environ[\"GOOGLE_CLOUD_REGION\"] = REGION"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1.1 Clone Repository\n",
        "\n",
        "**Why are we doing this?**\n",
        "Google Colab is a temporary virtual machine. It starts empty. The code for our agents (`main.py`, `Dockerfile`) lives in GitHub. We need to `git clone` (download) that code into this machine so we can build and deploy it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!git clone https://github.com/sangalo20/Serverless-agents-cloudrun.git\n",
        "%cd Serverless-agents-cloudrun"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1.2 Define Dockerfiles\n",
        "\n",
        "**Infrastructure as Code**\n",
        "To give us full control, we will define our Dockerfiles right here in the notebook. This allows us to see exactly how our container is built and make changes if needed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile librarian/Dockerfile\n",
        "FROM python:3.11-slim\n",
        "\n",
        "WORKDIR /app\n",
        "\n",
        "COPY requirements.txt .\n",
        "RUN pip install --no-cache-dir -r requirements.txt\n",
        "\n",
        "COPY . .\n",
        "\n",
        "# Run with Gunicorn\n",
        "CMD [\"gunicorn\", \"--bind\", \"0.0.0.0:8080\", \"--workers\", \"1\", \"--threads\", \"8\", \"--timeout\", \"0\", \"main:app\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile guide/Dockerfile\n",
        "FROM python:3.11-slim\n",
        "\n",
        "WORKDIR /app\n",
        "\n",
        "COPY requirements.txt .\n",
        "RUN pip install --no-cache-dir -r requirements.txt\n",
        "\n",
        "COPY . .\n",
        "\n",
        "# Run with Gunicorn\n",
        "CMD [\"gunicorn\", \"--bind\", \"0.0.0.0:8080\", \"--workers\", \"1\", \"--threads\", \"8\", \"--timeout\", \"0\", \"main:app\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Enable APIs\n",
        "\n",
        "**What are these?**\n",
        "Google Cloud services are not enabled by default. We need to turn on the specific services we plan to use:\n",
        "*   `run.googleapis.com`: **Cloud Run** (to run our containers).\n",
        "*   `eventarc.googleapis.com`: **Eventarc** (to trigger the Librarian when a file is uploaded).\n",
        "*   `aiplatform.googleapis.com`: **Vertex AI** (to use the Gemini model).\n",
        "*   `firestore.googleapis.com`: **Firestore** (our database).\n",
        "*   `cloudbuild.googleapis.com`: **Cloud Build** (to build our Docker containers).\n",
        "*   `storage.googleapis.com`: **Cloud Storage** (to store the PDF files).\n",
        "*   `artifactregistry.googleapis.com`: **Artifact Registry** (to store our Docker images)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!gcloud services enable run.googleapis.com eventarc.googleapis.com aiplatform.googleapis.com firestore.googleapis.com cloudbuild.googleapis.com storage.googleapis.com artifactregistry.googleapis.com"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Create Infrastructure\n",
        "\n",
        "**The Plan:**\n",
        "1.  **Cloud Storage Bucket**: We need a place to upload our conference schedules (PDFs). This bucket will act as the \"Inbox\" for our Librarian agent.\n",
        "2.  **Permissions**: We ensure our build service account has permission to write logs, save images, access Vertex AI, and write to Firestore.\n",
        "3.  **Firestore Database**: We need a fast, serverless database to store the *summarized knowledge* and the *chat history*. We use Firestore in \"Native\" mode.\n",
        "4.  **Artifact Registry**: We need a repository to store our Docker images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "BUCKET_NAME = f\"{PROJECT_ID}-knowledge-base\"\n",
        "!gsutil mb -l {REGION} gs://{BUCKET_NAME}\n",
        "print(f\"Created bucket: {BUCKET_NAME}\")\n",
        "\n",
        "# Create Firestore in Native mode (if not exists)\n",
        "!gcloud firestore databases create --location={REGION} --type=firestore-native\n",
        "\n",
        "# Create Artifact Registry Repository\n",
        "!gcloud artifacts repositories create containers --repository-format=docker --location={REGION} --description=\"Docker repository\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3.1 Setup Permissions\n",
        "\n",
        "**Granting Access**\n",
        "We need to ensure our build service account has permission to write logs, save images, access Vertex AI, and write to Firestore."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get Project Number and Service Account\n",
        "PROJECT_NUMBER = !gcloud projects describe {PROJECT_ID} --format='value(projectNumber)'\n",
        "PROJECT_NUMBER = PROJECT_NUMBER[0]\n",
        "SERVICE_ACCOUNT = f\"{PROJECT_NUMBER}-compute@developer.gserviceaccount.com\"\n",
        "\n",
        "# Grant permissions for Cloud Build and Runtime (Logging, Artifact Registry, Vertex AI, Firestore)\n",
        "!gcloud projects add-iam-policy-binding {PROJECT_ID} --member=serviceAccount:{SERVICE_ACCOUNT} --role=roles/logging.logWriter\n",
        "!gcloud projects add-iam-policy-binding {PROJECT_ID} --member=serviceAccount:{SERVICE_ACCOUNT} --role=roles/artifactregistry.writer\n",
        "!gcloud projects add-iam-policy-binding {PROJECT_ID} --member=serviceAccount:{SERVICE_ACCOUNT} --role=roles/storage.admin\n",
        "!gcloud projects add-iam-policy-binding {PROJECT_ID} --member=serviceAccount:{SERVICE_ACCOUNT} --role=roles/aiplatform.user\n",
        "!gcloud projects add-iam-policy-binding {PROJECT_ID} --member=serviceAccount:{SERVICE_ACCOUNT} --role=roles/datastore.user\n",
        "\n",
        "# Grant Pub/Sub Publisher to Cloud Storage Service Agent (required for Eventarc)\n",
        "GCS_SERVICE_AGENT = f\"service-{PROJECT_NUMBER}@gs-project-accounts.iam.gserviceaccount.com\"\n",
        "!gcloud projects add-iam-policy-binding {PROJECT_ID} --member=serviceAccount:{GCS_SERVICE_AGENT} --role=roles/pubsub.publisher"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Build \"The Librarian\" Service\n",
        "\n",
        "**Step 1: Build Container**\n",
        "We use `gcloud builds submit` to package our python code (`librarian/main.py`) into a Docker container image. This image is stored in Artifact Registry and is ready to be deployed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "SERVICE_NAME_LIBRARIAN = \"librarian\"\n",
        "!gcloud builds submit --tag {REGION}-docker.pkg.dev/{PROJECT_ID}/containers/{SERVICE_NAME_LIBRARIAN} librarian/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4.1 Deploy \"The Librarian\" Service\n",
        "\n",
        "**Step 2: Deploy to Cloud Run**\n",
        "Now we take the image we just built and deploy it to Cloud Run. We use `--allow-unauthenticated` so that Eventarc can easily trigger it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!gcloud run deploy {SERVICE_NAME_LIBRARIAN} --image {REGION}-docker.pkg.dev/{PROJECT_ID}/containers/{SERVICE_NAME_LIBRARIAN} --region {REGION} --allow-unauthenticated"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Build \"The Guide\" Service\n",
        "\n",
        "**Step 1: Build Container**\n",
        "Similar to the Librarian, we first build the container image for the Guide service."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "SERVICE_NAME_GUIDE = \"guide\"\n",
        "!gcloud builds submit --tag {REGION}-docker.pkg.dev/{PROJECT_ID}/containers/{SERVICE_NAME_GUIDE} guide/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5.1 Deploy \"The Guide\" Service\n",
        "\n",
        "**Step 2: Deploy to Cloud Run**\n",
        "We deploy the Guide service. This service will host the chat endpoint."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!gcloud run deploy {SERVICE_NAME_GUIDE} --image {REGION}-docker.pkg.dev/{PROJECT_ID}/containers/{SERVICE_NAME_GUIDE} --region {REGION} --allow-unauthenticated"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Wire it up with Eventarc\n",
        "\n",
        "**The Magic Glue**\n",
        "Right now, the Librarian service is running, but it doesn't know when a file is uploaded. We need **Eventarc** to bridge the gap.\n",
        "\n",
        "We create a **Trigger** that says:\n",
        "*   **IF** a file is `finalized` (uploaded) ...\n",
        "*   **IN** the specific bucket `{BUCKET_NAME}` ...\n",
        "*   **THEN** send a POST request to the `{SERVICE_NAME_LIBRARIAN}` service.\n",
        "\n",
        "*Note: We also grant the necessary IAM permissions so Eventarc is allowed to call our Cloud Run service.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Grant permission to the Compute Engine service account (default for Eventarc)\n",
        "PROJECT_NUMBER = !gcloud projects describe {PROJECT_ID} --format='value(projectNumber)'\n",
        "PROJECT_NUMBER = PROJECT_NUMBER[0]\n",
        "SERVICE_ACCOUNT = f\"{PROJECT_NUMBER}-compute@developer.gserviceaccount.com\"\n",
        "\n",
        "!gcloud projects add-iam-policy-binding {PROJECT_ID} --member=serviceAccount:{SERVICE_ACCOUNT} --role=roles/eventarc.eventReceiver\n",
        "!gcloud projects add-iam-policy-binding {PROJECT_ID} --member=serviceAccount:{SERVICE_ACCOUNT} --role=roles/run.invoker\n",
        "\n",
        "# Create the trigger\n",
        "!gcloud eventarc triggers create librarian-trigger \\\n",
        "  --location={REGION} \\\n",
        "  --destination-run-service={SERVICE_NAME_LIBRARIAN} \\\n",
        "  --destination-run-region={REGION} \\\n",
        "  --event-filters=\"type=google.cloud.storage.object.v1.finalized\" \\\n",
        "  --event-filters=\"bucket={BUCKET_NAME}\" \\\n",
        "  --service-account={SERVICE_ACCOUNT}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Test it!\n",
        "\n",
        "**Interactive UI**\n",
        "Let's test our agents with a real UI! Use the buttons below to upload any PDF or Text file, and then chat with your agent."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "from google.colab import files\n",
        "import requests\n",
        "import os\n",
        "\n",
        "# --- Configuration ---\n",
        "# Get Guide URL dynamically\n",
        "try:\n",
        "    GUIDE_URL = !gcloud run services describe {SERVICE_NAME_GUIDE} --region {REGION} --format='value(status.url)'\n",
        "    GUIDE_URL = GUIDE_URL[0]\n",
        "except:\n",
        "    print(\"Error: Could not find Guide service URL. Make sure it is deployed.\")\n",
        "    GUIDE_URL = \"\"\n",
        "\n",
        "SESSION_ID = \"interactive-session\"\n",
        "\n",
        "# --- UI Elements ---\n",
        "\n",
        "# 1. Upload Section\n",
        "upload_btn = widgets.Button(description=\"Upload Document\", button_style='info', icon='upload')\n",
        "upload_out = widgets.Output()\n",
        "\n",
        "def on_upload_clicked(b):\n",
        "    with upload_out:\n",
        "        upload_out.clear_output()\n",
        "        print(\"Select a file to upload...\")\n",
        "        uploaded = files.upload()\n",
        "        for filename in uploaded.keys():\n",
        "            print(f\"Uploading {filename} to {BUCKET_NAME}...\")\n",
        "            !gsutil cp \"{filename}\" gs://{BUCKET_NAME}/{filename}\n",
        "            print(f\"✅ {filename} uploaded! The Librarian is processing it (wait ~10-20s)...\")\n",
        "\n",
        "upload_btn.on_click(on_upload_clicked)\n",
        "\n",
        "# 2. Chat Section\n",
        "chat_history = widgets.Output(layout={'border': '1px solid #ccc', 'height': '300px', 'overflow_y': 'scroll'})\n",
        "user_input = widgets.Text(placeholder='Ask a question about your document...', layout={'width': '70%'})\n",
        "send_btn = widgets.Button(description=\"Send\", button_style='primary')\n",
        "\n",
        "def on_send_clicked(b):\n",
        "    question = user_input.value\n",
        "    if not question: return\n",
        "    \n",
        "    # Display User Message\n",
        "    with chat_history:\n",
        "        print(f\"You: {question}\")\n",
        "    \n",
        "    user_input.value = '' # Clear input\n",
        "    \n",
        "    # Call API\n",
        "    try:\n",
        "        response = requests.post(f\"{GUIDE_URL}/chat\", json={\"session_id\": SESSION_ID, \"query\": question})\n",
        "        if response.status_code == 200:\n",
        "            data = response.json()\n",
        "            answer = data.get('answer', 'No answer received.')\n",
        "            with chat_history:\n",
        "                print(f\"Agent: {answer}\\n\")\n",
        "        else:\n",
        "            with chat_history:\n",
        "                print(f\"Error: {response.status_code} - {response.text}\\n\")\n",
        "    except Exception as e:\n",
        "        with chat_history:\n",
        "            print(f\"Connection Error: {e}\\n\")\n",
        "\n",
        "send_btn.on_click(on_send_clicked)\n",
        "user_input.on_submit(on_send_clicked)\n",
        "\n",
        "# Layout\n",
        "print(f\"Connected to Guide Agent at: {GUIDE_URL}\")\n",
        "display(widgets.VBox([\n",
        "    widgets.HTML(\"<h3>1. Knowledge Base</h3>\"),\n",
        "    upload_btn,\n",
        "    upload_out,\n",
        "    widgets.HTML(\"<hr><h3>2. Chat Interface</h3>\"),\n",
        "    chat_history,\n",
        "    widgets.HBox([user_input, send_btn])\n",
        "]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Cleanup\n",
        "\n",
        "**Clean up your resources**\n",
        "To avoid incurring charges, delete the resources used in this workshop."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Starting cleanup...\\n\")\n",
        "\n",
        "# 1. Delete Eventarc Trigger\n",
        "print(f\"Deleting Eventarc trigger: librarian-trigger...\")\n",
        "!gcloud eventarc triggers delete librarian-trigger --location={REGION} --quiet\n",
        "print(\"✅ Eventarc trigger deleted.\\n\")\n",
        "\n",
        "# 2. Delete Cloud Run Services\n",
        "print(f\"Deleting Cloud Run service: {SERVICE_NAME_LIBRARIAN}...\")\n",
        "!gcloud run services delete {SERVICE_NAME_LIBRARIAN} --region {REGION} --quiet\n",
        "print(f\"✅ Service {SERVICE_NAME_LIBRARIAN} deleted.\\n\")\n",
        "\n",
        "print(f\"Deleting Cloud Run service: {SERVICE_NAME_GUIDE}...\")\n",
        "!gcloud run services delete {SERVICE_NAME_GUIDE} --region {REGION} --quiet\n",
        "print(f\"✅ Service {SERVICE_NAME_GUIDE} deleted.\\n\")\n",
        "\n",
        "# 3. Delete Cloud Storage Bucket\n",
        "print(f\"Deleting Bucket: {BUCKET_NAME}...\")\n",
        "!gsutil rm -r gs://{BUCKET_NAME}\n",
        "print(f\"✅ Bucket {BUCKET_NAME} deleted.\\n\")\n",
        "\n",
        "# 4. Delete Artifact Registry Repository\n",
        "print(\"Deleting Artifact Registry repository: containers...\")\n",
        "!gcloud artifacts repositories delete containers --location={REGION} --quiet\n",
        "print(\"✅ Artifact Registry repository deleted.\\n\")\n",
        "\n",
        "# 5. Delete Firestore Database\n",
        "print(\"Deleting Firestore database: (default)...\")\n",
        "!gcloud firestore databases delete --database=\"(default)\" --quiet\n",
        "print(\"✅ Firestore database deleted.\\n\")\n",
        "\n",
        "print(\"Cleanup complete!\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
